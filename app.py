import streamlit as st
from streamlit_geolocation import streamlit_geolocation
import pandas as pd
from math import radians, sin, cos, sqrt, atan2
import os
import re
import glob

# Langchain ê´€ë ¨ import
from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import CSVLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
load_dotenv()

st.set_page_config(page_title="ê´€ê´‘ì§€ ì¶”ì²œ ì±—ë´‡", layout="wide")

# --- íŒŒì¼ ê²½ë¡œ ì •ì˜ (ìƒìˆ˜) ---
VECTOR_DB_PATH = "faiss_tourist_attractions"

# ë¡œë“œí•  ê°œë³„ ê´€ê´‘ì§€ CSV íŒŒì¼ ëª©ë¡ì„ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.
# **ì—¬ê¸°ë¥¼ ì‹¤ì œ CSV íŒŒì¼ ê²½ë¡œì— ë§žê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”!**
# Streamlit Cloudì—ì„œëŠ” ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
TOUR_CSV_FILES = [
    "./ê²½ê¸°ë„ì—­ì‚¬ê´€ê´‘ì§€í˜„í™©.csv",
    "./ê²½ê¸°ë„ìžì—°ê´€ê´‘ì§€í˜„í™©.csv",
    "./ê²½ê¸°ë„ì²´í—˜ê´€ê´‘ì§€í˜„í™©.csv",
    "./ê²½ê¸°ë„í…Œë§ˆê´€ê´‘ì§€í˜„í™©.csv",
    "./ê´€ê´‘ì§€ì •ë³´í˜„í™©(ì œê³µí‘œì¤€).csv",
    "./ê´€ê´‘ì§€í˜„í™©.csv",
    # í•„ìš”ì— ë”°ë¼ ë‹¤ë¥¸ CSV íŒŒì¼ë“¤ì„ ì—¬ê¸°ì— ì¶”ê°€í•˜ì„¸ìš”.
]

# --- ì´ˆê¸° íŒŒì¼ ì¡´ìž¬ ì—¬ë¶€ í™•ì¸ ---
# ëª¨ë“  í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì´ ì¡´ìž¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
required_files = TOUR_CSV_FILES
for f_path in required_files:
    if not os.path.exists(f_path):
        st.error(f"í•„ìˆ˜ ë°ì´í„° íŒŒì¼ '{f_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. (Streamlit Cloudì—ì„œëŠ” í•´ë‹¹ íŒŒì¼ë“¤ì´ Git ë¦¬í¬ì§€í† ë¦¬ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)")
        st.stop()


# --- 1. ì„¤ì • ë° ì´ˆê¸°í™” í•¨ìˆ˜ ---
def setup_environment():
    """
    í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Streamlit secretsì—ì„œ OpenAI API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    Streamlit Cloud í™˜ê²½ì—ì„œëŠ” st.secretsë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” .env íŒŒì¼ì„ ë¡œë“œí•˜ê±°ë‚˜ ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    if 'OPENAI_API_KEY' in st.secrets:
        st.success("âœ… OpenAI API í‚¤ë¥¼ Streamlit Secretsì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return st.secrets['OPENAI_API_KEY']
    else:
        load_dotenv() # ë¡œì»¬ ê°œë°œ ì‹œ .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            st.success("âœ… OpenAI API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜(.env íŒŒì¼ ë˜ëŠ” ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜)ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Cloudì—ì„œëŠ” secrets.tomlì— í‚¤ë¥¼ ì„¤ì •í•˜ê±°ë‚˜, ë¡œì»¬ì—ì„œëŠ” .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return api_key


def initialize_streamlit_app():
    """Streamlit ì•±ì˜ ê¸°ë³¸ íŽ˜ì´ì§€ ì„¤ì • ë° ì œëª©ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    st.title("ðŸ—ºï¸ ìœ„ì¹˜ ê¸°ë°˜ ê´€ê´‘ì§€ ì¶”ì²œ ë° ì—¬í–‰ ê³„íš ì±—ë´‡")

# --- 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_data
def load_specific_tour_data(file_paths_list): # utf8_files íŒŒë¼ë¯¸í„° ì œê±°
    """ì§€ì •ëœ CSV íŒŒì¼ ëª©ë¡ì„ ë¡œë“œí•˜ê³ , ëª¨ë“  íŒŒì¼ì— CP949 ì¸ì½”ë”©ì„ ì ìš©í•˜ì—¬ ë³‘í•©í•©ë‹ˆë‹¤."""
    combined_df = pd.DataFrame()

    if not file_paths_list:
        st.error("ë¡œë“œí•  ê´€ê´‘ì§€ CSV íŒŒì¼ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `TOUR_CSV_FILES`ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    for file_path in file_paths_list:
        if not os.path.exists(file_path):
            st.warning(f"'{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤. (Streamlit Cloudì—ì„œëŠ” í•´ë‹¹ íŒŒì¼ë“¤ì´ Git ë¦¬í¬ì§€í† ë¦¬ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)")
            continue

        # ëª¨ë“  íŒŒì¼ì— CP949 ì¸ì½”ë”© ì ìš©
        current_encoding = 'cp949' # ì˜¬ë°”ë¥¸ ì¸ì½”ë”©ìœ¼ë¡œ ë‹¤ì‹œ í™•ì¸

        try:
            df = pd.read_csv(file_path, encoding=current_encoding)
            df.columns = df.columns.str.strip()

            if "ìœ„ë„" not in df.columns or "ê²½ë„" not in df.columns:
                st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ì€ 'ìœ„ë„', 'ê²½ë„' ì»¬ëŸ¼ì´ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤.")
                continue

            name_col = None
            for candidate in ["ê´€ê´‘ì§€ëª…", "ê´€ê´‘ì •ë³´ëª…","ê´€ê´‘ì§€"]:
                if candidate in df.columns:
                    name_col = candidate
                    break

            if name_col is None:
                df["ê´€ê´‘ì§€ëª…"] = "ì´ë¦„ ì—†ìŒ"
            else:
                df["ê´€ê´‘ì§€ëª…"] = df[name_col]

            address_col = None
            for candidate in ["ì •ì œë„ë¡œëª…ì£¼ì†Œ","ì •ì œì§€ë²ˆì£¼ì†Œ","ì†Œìž¬ì§€ë„ë¡œëª…ì£¼ì†Œ","ì†Œìž¬ì§€ì§€ë²ˆì£¼ì†Œ","ê´€ê´‘ì§€ì†Œìž¬ì§€ì§€ë²ˆì£¼ì†Œ","ê´€ê´‘ì§€ì†Œìž¬ì§€ë„ë¡œëª…ì£¼ì†Œ"]:
                if candidate in df.columns:
                    address_col = candidate
                    break

            if address_col is None:
                df["ì†Œìž¬ì§€ë„ë¡œëª…ì£¼ì†Œ"] = "ì£¼ì†Œ ì—†ìŒ"
            else:
                df["ì†Œìž¬ì§€ë„ë¡œëª…ì£¼ì†Œ"] = df[address_col]

            df = df[["ìœ„ë„", "ê²½ë„", "ê´€ê´‘ì§€ëª…", "ì†Œìž¬ì§€ë„ë¡œëª…ì£¼ì†Œ"]]

            combined_df = pd.concat([combined_df, df], ignore_index=True)

        except Exception as e:
            st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ ({current_encoding} ì¸ì½”ë”© ì‹œë„) ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if combined_df.empty:
        st.error("ì§€ì •ëœ íŒŒì¼ë“¤ì—ì„œ ìœ íš¨í•œ ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. `TOUR_CSV_FILES`ì™€ íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    return combined_df


# --- ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ë° ìºì‹± ---
@st.cache_resource
def load_and_create_vectorstore_from_specific_files(tour_csv_files_list): # utf8_files íŒŒë¼ë¯¸í„° ì œê±°
    """ì§€ì •ëœ CSV íŒŒì¼ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    all_city_tour_docs = []
    for file_path in tour_csv_files_list:
        if not os.path.exists(file_path):
            st.warning(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„±ì„ ìœ„í•´ '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤.")
            continue

        # ëª¨ë“  íŒŒì¼ì— CP949 ì¸ì½”ë”© ì ìš©
        current_encoding = 'cp949'

        try:
            city_tour_loader = CSVLoader(file_path=file_path, encoding=current_encoding, csv_args={'delimiter': ','})
            all_city_tour_docs.extend(city_tour_loader.load())
        except Exception as e:
            st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ ({current_encoding} ì¸ì½”ë”© ì‹œë„) ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë²¡í„°ìŠ¤í† ì–´): {e}")

    all_documents = all_city_tour_docs

    if not all_documents:
        st.error("ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)
    docs = text_splitter.split_documents(all_documents)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(VECTOR_DB_PATH)
    return vectorstore

@st.cache_resource()
def get_vectorstore_cached(tour_csv_files_list): # utf8_files íŒŒë¼ë¯¸í„° ì œê±°
    """ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    cache_key = tuple(sorted(tour_csv_files_list)) # ìºì‹œ í‚¤ì—ì„œ utf8_files ì œê±°

    if os.path.exists(VECTOR_DB_PATH):
        try:
            return FAISS.load_local(
                VECTOR_DB_PATH,
                OpenAIEmbeddings(),
                allow_dangerous_deserialization=True
            )
        except Exception as e:
            st.warning(f"ê¸°ì¡´ ë²¡í„° DB ë¡œë”© ì‹¤íŒ¨: {e}. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            return load_and_create_vectorstore_from_specific_files(tour_csv_files_list) # ì¸ìž ì œê±°
    else:
        return load_and_create_vectorstore_from_specific_files(tour_csv_files_list) # ì¸ìž ì œê±°


# --- Haversine distance function ---
def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # Radius of Earth in kilometers
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    distance = R * c
    return distance

# --- 3. ì‚¬ìš©ìž ìž…ë ¥ ë° UI ë¡œì§ í•¨ìˆ˜ ---
def get_user_inputs_ui():
    """ì‚¬ìš©ìžë¡œë¶€í„° ë‚˜ì´, ì—¬í–‰ ìŠ¤íƒ€ì¼, í˜„ìž¬ ìœ„ì¹˜, ê·¸ë¦¬ê³  ì¶”ê°€ ì—¬í–‰ ê³„íš ì •ë³´ë¥¼ ìž…ë ¥ë°›ëŠ” UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("#### ì‚¬ìš©ìž ì •ë³´ ìž…ë ¥")
        age = st.selectbox("ë‚˜ì´ëŒ€ ì„ íƒ", ["10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€ ì´ìƒ"], key='age_selectbox')
        travel_style = st.multiselect("ì—¬í–‰ ìŠ¤íƒ€ì¼", ["ìžì—°", "ì—­ì‚¬", "ì²´í—˜", "íœ´ì‹", "ë¬¸í™”", "ê°€ì¡±", "ì•¡í‹°ë¹„í‹°"], key='travel_style_multiselect')

    st.header("â‘  ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°")
    location = streamlit_geolocation()

    user_lat_final, user_lon_final = None, None

    if location and "latitude" in location and "longitude" in location:
        temp_lat = location.get("latitude")
        temp_lon = location.get("longitude")
        if temp_lat is not None and temp_lon is not None:
            user_lat_final = temp_lat
            user_lon_final = temp_lon
            st.success(f"ðŸ“ í˜„ìž¬ ìœ„ì¹˜: ìœ„ë„ {user_lat_final:.7f}, ê²½ë„ {user_lon_final:.7f}")
        else:
            st.warning("ðŸ“ ìœ„ì¹˜ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ìž…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        st.warning("ìœ„ì¹˜ ì •ë³´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ìœ„ë„, ê²½ë„ë¥¼ ìž…ë ¥í•´ ì£¼ì„¸ìš”.")

    if user_lat_final is None or user_lon_final is None:
        default_lat = st.session_state.get("user_lat", 37.5665) # ì„œìš¸ ì‹œì²­ ê¸°ë³¸ ìœ„ë„
        default_lon = st.session_state.get("user_lon", 126.9780) # ì„œìš¸ ì‹œì²­ ê¸°ë³¸ ê²½ë„

        st.subheader("ì§ì ‘ ìœ„ì¹˜ ìž…ë ¥ (ì„ íƒ ì‚¬í•­)")
        manual_lat = st.number_input("ìœ„ë„", value=float(default_lat), format="%.7f", key="manual_lat_input")
        manual_lon = st.number_input("ê²½ë„", value=float(default_lon), format="%.7f", key="manual_lon_input")

        if manual_lat != 0.0 or manual_lon != 0.0:
            user_lat_final = manual_lat
            user_lon_final = manual_lon
        else:
            user_lat_final = None
            user_lon_final = None
            st.error("ìœ íš¨í•œ ìœ„ë„ ë° ê²½ë„ ê°’ì´ ìž…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 0ì´ ì•„ë‹Œ ê°’ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.")

    st.session_state.user_lat = user_lat_final
    st.session_state.user_lon = user_lon_final

    st.markdown("#### ì¶”ê°€ ì—¬í–‰ ê³„íš ì •ë³´")
    trip_duration_days = st.number_input("ì—¬í–‰ ê¸°ê°„ (ì¼)", min_value=1, value=3, key='trip_duration')
    estimated_budget = st.number_input("ì˜ˆìƒ ì˜ˆì‚° (ì›, ì´ ê¸ˆì•¡)", min_value=0, value=500000, step=10000, key='estimated_budget')
    num_travelers = st.number_input("ì—¬í–‰ ì¸ì› (ëª…)", min_value=1, value=2, key='num_travelers')
    special_requests = st.text_area("íŠ¹ë³„ížˆ ê³ ë ¤í•  ì‚¬í•­ (ì„ íƒ ì‚¬í•­)", help="ì˜ˆ: ìœ ëª¨ì°¨ ì‚¬ìš©, ê³ ë ¹ìž ë™ë°˜, íŠ¹ì • ìŒì‹ ì„ í˜¸ ë“±", key='special_requests')

    return age, travel_style, user_lat_final, user_lon_final, trip_duration_days, estimated_budget, num_travelers, special_requests

# --- 4. ì¶”ì²œ ë¡œì§ í•¨ìˆ˜ (Langchain API ë³€ê²½: create_retrieval_chain ì‚¬ìš©) (í”„ë¡¬í”„íŠ¸ ìˆ˜ì •) ---
@st.cache_resource
def get_qa_chain(_vectorstore):
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0.7)

    # 1. ë¬¸ì„œ ì²´ì¸ (í”„ë¡¬í”„íŠ¸ + ë¬¸ì„œ ê²°í•©) ìƒì„±
    qa_prompt = PromptTemplate.from_template(
        """
ë‹¹ì‹ ì€ ì‚¬ìš©ìž ìœ„ì¹˜ ê¸°ë°˜ ì—¬í–‰ì§€ ì¶”ì²œ ë° ìƒì„¸ ì—¬í–‰ ê³„íš ìˆ˜ë¦½ ì±—ë´‡ìž…ë‹ˆë‹¤.
ì‚¬ìš©ìžì˜ ë‚˜ì´ëŒ€, ì—¬í–‰ ì„±í–¥, í˜„ìž¬ ìœ„ì¹˜ ì •ë³´, ê·¸ë¦¬ê³  ë‹¤ìŒì˜ ì¶”ê°€ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìžê°€ ìž…ë ¥í•œ ì§ˆë¬¸ì— ê°€ìž¥ ì í•©í•œ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½í•´ ì£¼ì„¸ìš”.
**ê´€ê´‘ì§€ ì¶”ì²œ ì‹œ ì‚¬ìš©ìž ìœ„ì¹˜ë¡œë¶€í„°ì˜ ê±°ë¦¬ëŠ” ì‹œìŠ¤í…œì´ ìžë™ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¶”ê°€í•  ê²ƒì´ë¯€ë¡œ, ë‹µë³€ì—ì„œ ê±°ë¦¬ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
íŠ¹ížˆ, ì‚¬ìš©ìžì˜ í˜„ìž¬ ìœ„ì¹˜({user_lat}, {user_lon})ì—ì„œ ê°€ê¹Œìš´ ìž¥ì†Œë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì¶”ì²œí•˜ê³  ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”.
ê¼­ê¼­ ì‚¬ìš©ìž í˜„ìž¬ ìœ„ì¹˜ì™€ ê°€ê¹Œìš´ ê³³ì„ ìµœìš°ì„ ìœ¼ë¡œ í•´ì£¼ê³  ì‚¬ìš©ìžê°€ ì„ íƒí•œ ì„±í–¥ì— ë§žê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

[ê´€ê´‘ì§€ ë°ì´í„°]
{context}

[ì‚¬ìš©ìž ì •ë³´]
ë‚˜ì´ëŒ€: {age}
ì—¬í–‰ ì„±í–¥: {travel_style}
í˜„ìž¬ ìœ„ì¹˜ (ìœ„ë„, ê²½ë„): {user_lat}, {user_lon}
ì—¬í–‰ ê¸°ê°„: {trip_duration_days}ì¼
ì˜ˆìƒ ì˜ˆì‚°: {estimated_budget}ì›
ì—¬í–‰ ì¸ì›: {num_travelers}ëª…
íŠ¹ë³„ ê³ ë ¤ì‚¬í•­: {special_requests}

[ì‚¬ìš©ìž ì§ˆë¬¸]
{input}

ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ìƒì„¸í•œ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”:
1.  **ê´€ê´‘ì§€ ì¶”ì²œ:** ì§ˆë¬¸ì— ë¶€í•©í•˜ê³ , ì‚¬ìš©ìž ìœ„ì¹˜ì—ì„œ ê°€ê¹Œìš´ 1~3ê°œì˜ ì£¼ìš” ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê³ , ê° ê´€ê´‘ì§€ì— ëŒ€í•œ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
    * ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª…]
    * ì£¼ì†Œ: [ì£¼ì†Œ]
    * ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´]
    **[ì°¸ê³ : ì‚¬ìš©ìž ìœ„ì¹˜ ê¸°ì¤€ ê±°ë¦¬ëŠ” ì‹œìŠ¤í…œì´ ìžë™ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¶”ê°€í•  ê²ƒì´ë¯€ë¡œ, ì´ í•­ëª©ì€ ì œì™¸í•©ë‹ˆë‹¤.]**
      
2.  **ì¶”ì²œëœ ê´€ê´‘ì§€ë¥¼ í¬í•¨í•˜ì—¬, ì‚¬ìš©ìž ì •ë³´ì™€ ì§ˆë¬¸ì— ê¸°ë°˜í•œ {trip_duration_days}ì¼ê°„ì˜ ìƒì„¸ ì—¬í–‰ ê³„íšì„ ì¼ìžë³„ë¡œ êµ¬ì„±í•´ ì£¼ì„¸ìš”.**
    * ê° ë‚ ì§œë³„ë¡œ ë°©ë¬¸í•  ìž¥ì†Œ(ì‹ë‹¹, ì¹´íŽ˜, ê¸°íƒ€ í™œë™ í¬í•¨), ì˜ˆìƒ ì‹œê°„, ê°„ë‹¨í•œ í™œë™ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.
    * ì˜ˆì‚°ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ì‹ì‚¬ ìž¥ì†Œë‚˜ í™œë™ì„ ì œì•ˆí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
    * ì´ë™ ê²½ë¡œ(ì˜ˆ: "ë„ë³´ 15ë¶„", "ë²„ìŠ¤ 30ë¶„")ë¥¼ ê°„ëžµí•˜ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.
    * ê³„íšì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ìž‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

[ë‹µë³€ ì˜ˆì‹œ]
**ì¶”ì²œ ê´€ê´‘ì§€:**
- ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª… 1]
  - ì£¼ì†Œ: [ì£¼ì†Œ 1]
  - ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´ 1]
- ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª… 2]
  - ì£¼ì†Œ: [ì£¼ì†Œ 2]
  - ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´ 2]

**ìƒì„¸ ì—¬í–‰ ê³„íš ({trip_duration_days}ì¼):**

**1ì¼ì°¨:**
- ì˜¤ì „ (9:00 - 12:00): [ê´€ê´‘ì§€ëª… 1] ë°©ë¬¸ (ì˜ˆ: ì—­ì‚¬ íƒë°©, ë°•ë¬¼ê´€ ê´€ëžŒ).
- ì ì‹¬ (12:00 - 13:00): [ê·¼ì²˜ ì‹ë‹¹ëª…] (ì˜ˆ: í•œì‹ ë§›ì§‘, {estimated_budget}ì›ì— ì í•©í•œ ë©”ë‰´)
- ì˜¤í›„ (13:00 - 17:00): [ê´€ê´‘ì§€ëª… 2] ë°©ë¬¸ (ì˜ˆ: ìžì—° ê²½ê´€ ê°ìƒ, ì‚°ì±…). [ê´€ê´‘ì§€ëª… 1]ì—ì„œ ë²„ìŠ¤ 30ë¶„ ì´ë™.
- ì €ë… (17:00 ì´í›„): [íŠ¹ì • í™œë™ ë˜ëŠ” ìžìœ  ì‹œê°„]

**2ì¼ì°¨:**
- ... (ì´í›„ ë‚ ì§œë³„ ê³„íš) ...
"""
    )
    document_chain = create_stuff_documents_chain(llm, qa_prompt)
    retriever = _vectorstore.as_retriever(search_kwargs={"k": 15})
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    return retrieval_chain


# --- 5. ë©”ì¸ ì•± ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    openai_api_key = setup_environment()
    if not openai_api_key:
        st.stop()

    initialize_streamlit_app()

    vectorstore = get_vectorstore_cached(TOUR_CSV_FILES) # ì¸ìž ì œê±°

    # --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë° ì´ì „ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ---
    # `conversations`ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜, ê¸°ì¡´ì— `messages`ê°€ ë‚¨ì•„ìžˆë‹¤ë©´ ëª¨ë‘ ì´ˆê¸°í™”
    # ì´ëŠ” ì´ì „ì— ì‚¬ìš©í•˜ë˜ `messages` í˜•ì‹ì´ ë‚¨ì•„ìžˆì„ ë•Œ ë°œìƒí•˜ëŠ” KeyErrorë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    if "conversations" not in st.session_state or "messages" in st.session_state:
        st.session_state.conversations = [] # ìƒˆë¡œìš´ í˜•ì‹ìœ¼ë¡œ ì´ˆê¸°í™”
        if "messages" in st.session_state:
            del st.session_state.messages # ì´ì „ í˜•ì‹ì€ ì‚­ì œ
        st.session_state.current_input = ""
        st.session_state.selected_conversation_index = None

    qa_chain = get_qa_chain(vectorstore)
    tour_data_df = load_specific_tour_data(TOUR_CSV_FILES)

    # Sidebar for previous conversations
    with st.sidebar:
        st.subheader("ðŸ’¡ ì´ì „ ëŒ€í™”")
        if st.session_state.conversations:
            # ìµœì‹  ëŒ€í™”ê°€ ìœ„ì— ì˜¤ë„ë¡ ì—­ìˆœìœ¼ë¡œ í‘œì‹œ
            for i, conv in enumerate(reversed(st.session_state.conversations)):
                # ì‹¤ì œ ì¸ë±ìŠ¤ë¥¼ ê³„ì‚° (ë’¤ì§‘ížŒ ìˆœì„œì— ë”°ë¼)
                original_index = len(st.session_state.conversations) - 1 - i
                
                # ì‚¬ìš©ìž ì§ˆë¬¸ì˜ ì²« ëª‡ ê¸€ìžë¥¼ ë”°ì™€ì„œ ë²„íŠ¼ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                # 'user_query' í‚¤ë¥¼ ì‚¬ìš© (ìƒˆë¡œìš´ ëŒ€í™” í˜•ì‹)
                preview_text = conv['user_query'][:30] + ('...' if len(conv['user_query']) > 30 else '')
                
                if st.button(f"ëŒ€í™” {original_index + 1}: {preview_text}", key=f"sidebar_conv_{original_index}"):
                    st.session_state.selected_conversation_index = original_index
                    st.rerun() # <--- st.rerun()ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.

        else:
            st.info("ì´ì „ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # Main content area
    age, travel_style_list, current_user_lat, current_user_lon, \
    trip_duration_days, estimated_budget, num_travelers, special_requests = get_user_inputs_ui()

    st.header("â‘¡ ì§ˆë¬¸í•˜ê¸°")
    user_query = st.text_input("ì–´ë–¤ ì—¬í–‰ì„ ê³„íší•˜ê³  ê³„ì‹ ê°€ìš”? (ì˜ˆ: ê°€ì¡±ê³¼ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìžˆëŠ” ìžì—° í…Œë§ˆ ì—¬í–‰)", value=st.session_state.current_input, key="user_input")

    if st.button("ì—¬í–‰ ê³„íš ì¶”ì²œë°›ê¸°"):
        # ìƒˆë¡œìš´ ì§ˆë¬¸ ì‹œìž‘ ì‹œ, í˜„ìž¬ ì„ íƒëœ ëŒ€í™” ì´ˆê¸°í™”
        st.session_state.selected_conversation_index = None 

        lat_to_invoke = current_user_lat
        lon_to_invoke = current_user_lon

        age_to_invoke = age
        travel_style_to_invoke = ', '.join(travel_style_list) if travel_style_list else 'íŠ¹ì • ì—†ìŒ'
        trip_duration_days_to_invoke = trip_duration_days
        estimated_budget_to_invoke = estimated_budget
        num_travelers_to_invoke = num_travelers
        special_requests_to_invoke = special_requests

        st.write(f"**DEBUG: Invoke Parameters**")
        st.write(f"input (query): {user_query}")
        st.write(f"age: {age_to_invoke}")
        st.write(f"travel_style: {travel_style_to_invoke}")
        st.write(f"user_lat: {lat_to_invoke}")
        st.write(f"user_lon: {lon_to_invoke}")
        st.write(f"trip_duration_days: {trip_duration_days_to_invoke}")
        st.write(f"estimated_budget: {estimated_budget_to_invoke}")
        st.write(f"num_travelers: {num_travelers_to_invoke}")
        st.write(f"special_requests: {special_requests_to_invoke}")


        if lat_to_invoke is None or lon_to_invoke is None:
            st.warning("ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì¹˜ ì •ë³´ë¥¼ ìž…ë ¥í•˜ê±°ë‚˜ ê°€ì ¸ì™€ ì£¼ì„¸ìš”.")
        elif not user_query.strip():
            st.warning("ì§ˆë¬¸ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ìµœì ì˜ ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½ ì¤‘ìž…ë‹ˆë‹¤..."):
                try:
                    response = qa_chain.invoke({
                        "input": user_query,
                        "age": age_to_invoke,
                        "travel_style": travel_style_to_invoke,
                        "user_lat": lat_to_invoke,
                        "user_lon": lon_to_invoke,
                        "trip_duration_days": trip_duration_days_to_invoke,
                        "estimated_budget": estimated_budget_to_invoke,
                        "num_travelers": num_travelers_to_invoke,
                        "special_requests": special_requests_to_invoke
                    })

                    rag_result_text = response["answer"]

                    processed_output_lines = []
                    processed_place_names = set()

                    # LLM ì‘ë‹µì—ì„œ ê´€ê´‘ì§€ ì •ë³´ ì¶”ì¶œ ë° ê±°ë¦¬ ì¶”ê°€
                    for line in rag_result_text.split('\n'):
                        name_match = re.search(r"ê´€ê´‘ì§€ ì´ë¦„:\s*(.+)", line)

                        if name_match:
                            current_place_name = name_match.group(1).strip()
                            # ì´ë¯¸ ì²˜ë¦¬ëœ ê´€ê´‘ì§€ëŠ” ê±´ë„ˆë›°ì–´ ì¤‘ë³µ ë°©ì§€
                            if current_place_name not in processed_place_names:
                                processed_output_lines.append(line)
                                processed_place_names.add(current_place_name)

                                found_place_data = tour_data_df[
                                    (tour_data_df['ê´€ê´‘ì§€ëª…'].str.strip() == current_place_name) &
                                    (pd.notna(tour_data_df['ìœ„ë„'])) &
                                    (pd.notna(tour_data_df['ê²½ë„']))
                                ]

                                if not found_place_data.empty:
                                    place_lat = found_place_data['ìœ„ë„'].iloc[0]
                                    place_lon = found_place_data['ê²½ë„'].iloc[0]
                                    distance = haversine(lat_to_invoke, lon_to_invoke, place_lat, place_lon)
                                    processed_output_lines.append(f"- ì‚¬ìš©ìž ìœ„ì¹˜ ê¸°ì¤€ ê±°ë¦¬(km): ì•½ {distance:.2f} km")
                                else:
                                    processed_output_lines.append("- ì‚¬ìš©ìž ìœ„ì¹˜ ê¸°ì¤€ ê±°ë¦¬(km): ì •ë³´ ì—†ìŒ (ë°ì´í„° ë¶ˆì¼ì¹˜ ë˜ëŠ” ì¢Œí‘œ ëˆ„ë½)")
                            else:
                                pass # ì´ë¯¸ ì²˜ë¦¬ëœ ê´€ê´‘ì§€ëª…ì€ ê±´ë„ˆë›°ê¸°
                        else:
                            # 'ê±°ë¦¬(km):' ì •ë³´ê°€ ì´ë¯¸ í¬í•¨ëœ ë¼ì¸ì€ ì¤‘ë³µ ì¶”ê°€ ë°©ì§€ (í˜¹ì‹œ LLMì´ ë„£ì—ˆì„ ê²½ìš°)
                            if not re.search(r"ê±°ë¦¬\(km\):", line):
                                processed_output_lines.append(line)

                    final_display_text = "\n".join(processed_output_lines)
                    
                    # ìƒˆë¡œìš´ ëŒ€í™” ìŒì„ ì €ìž¥
                    st.session_state.conversations.append({
                        "user_query": user_query,
                        "chatbot_response": final_display_text
                    })

                    st.subheader("âœ… ì¶”ì²œ ê²°ê³¼ ë° ìƒì„¸ ì—¬í–‰ ê³„íš")
                    st.markdown(final_display_text)

                except ValueError as ve:
                    st.error(f"ì²´ì¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {ve}. ìž…ë ¥ í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.session_state.current_input = "" # ìž…ë ¥ì°½ ì´ˆê¸°í™”

    # --- ì„ íƒëœ ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ (ìƒˆë¡œìš´ ì„¹ì…˜) ---
    if st.session_state.selected_conversation_index is not None:
        st.markdown("---") # êµ¬ë¶„ì„  ì¶”ê°€
        st.header("ðŸ“– ì„ íƒëœ ì´ì „ ëŒ€í™” ë‚´ìš©")
        
        selected_conv = st.session_state.conversations[st.session_state.selected_conversation_index]
        
        st.subheader("ðŸ™‹â€â™‚ï¸ ì‚¬ìš©ìž ì§ˆë¬¸:")
        st.markdown(selected_conv['user_query'])
        
        st.subheader("ðŸ¤– ì±—ë´‡ ë‹µë³€:")
        st.markdown(selected_conv['chatbot_response'])
        
        st.markdown("---") # êµ¬ë¶„ì„  ì¶”ê°€
