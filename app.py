import streamlit as st
from streamlit_geolocation import streamlit_geolocation
import pandas as pd
from math import radians, sin, cos, sqrt, atan2
import os
import re
import glob
import io

# Langchain ê´€ë ¨ import
from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import CSVLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (ë¡œì»¬ ê°œë°œ ì‹œ ì‚¬ìš©. Streamlit Cloudì—ì„œëŠ” Secrets ì‚¬ìš© ê¶Œì¥)
load_dotenv()

st.set_page_config(page_title="âœˆï¸ ê´€ê´‘ì§€ ì¶”ì²œ ì±—ë´‡", layout="wide")

# --- íŒŒì¼ ê²½ë¡œ ì •ì˜ (ìƒìˆ˜) ---
# GitHub ì €ì¥ì†Œì— ì—…ë¡œë“œí•  ë•Œ ì´ ê²½ë¡œê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# ì˜ˆ: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— CSV íŒŒì¼ë“¤ì´ ìˆë‹¤ë©´ "./íŒŒì¼ëª….csv"
VECTOR_DB_PATH = "faiss_tourist_attractions"

# ë¡œë“œí•  ê°œë³„ ê´€ê´‘ì§€ CSV íŒŒì¼ ëª©ë¡ì„ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.
# ì´ íŒŒì¼ë“¤ì€ GitHub ì €ì¥ì†Œì˜ ì•± ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ìœ„ì¹˜ ë˜ëŠ” ì§€ì •ëœ ìƒëŒ€ ê²½ë¡œì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
TOUR_CSV_FILES = [
    "./ê²½ê¸°ë„ì—­ì‚¬ê´€ê´‘ì§€í˜„í™©.csv",
    "./ê²½ê¸°ë„ìì—°ê´€ê´‘ì§€í˜„í™©.csv",
    "./ê²½ê¸°ë„ì²´í—˜ê´€ê´‘ì§€í˜„í™©.csv",
    "./ê²½ê¸°ë„í…Œë§ˆê´€ê´‘ì§€í˜„í™©.csv",
    "./ê´€ê´‘ì§€ì •ë³´í˜„í™©(ì œê³µí‘œì¤€).csv",
    "./ê´€ê´‘ì§€í˜„í™©.csv",
    # í•„ìš”ì— ë”°ë¼ ë‹¤ë¥¸ CSV íŒŒì¼ë“¤ì„ ì—¬ê¸°ì— ì¶”ê°€í•˜ì„¸ìš”.
]

# --- ì´ˆê¸° íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ---
required_files = TOUR_CSV_FILES
for f_path in required_files:
    # GitHub ë°°í¬ ì‹œ, ì´ os.path.exists ê²€ì‚¬ëŠ” Git ì €ì¥ì†Œ ë‚´ì˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    if not os.path.exists(f_path):
        st.error(f"í•„ìˆ˜ ë°ì´í„° íŒŒì¼ '{f_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. (Streamlit Cloudì—ì„œëŠ” í•´ë‹¹ íŒŒì¼ë“¤ì´ Git ë¦¬í¬ì§€í† ë¦¬ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)")
        st.stop()


# --- 1. ì„¤ì • ë° ì´ˆê¸°í™” í•¨ìˆ˜ ---
def setup_environment():
    """
    í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Streamlit secretsì—ì„œ OpenAI API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    Streamlit Cloud í™˜ê²½ì—ì„œëŠ” st.secretsë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” .env íŒŒì¼ì„ ë¡œë“œí•˜ê±°ë‚˜ ì‹œìŠ¤í…œ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    if 'OPENAI_API_KEY' in st.secrets:
        return st.secrets['OPENAI_API_KEY']
    else:
        # load_dotenv()ëŠ” ì´ í•¨ìˆ˜ ë°”ê¹¥ì—ì„œ í•œ ë²ˆ í˜¸ì¶œë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìƒëµ
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            pass
        else:
            st.error("âŒ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Streamlit Cloudì—ì„œëŠ” secrets.tomlì— í‚¤ë¥¼ ì„¤ì •í•˜ê±°ë‚˜, ë¡œì»¬ì—ì„œëŠ” .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return api_key

# --- 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ---
@st.cache_data
def load_specific_tour_data(file_paths_list):
    """ì§€ì •ëœ CSV íŒŒì¼ ëª©ë¡ì„ ë¡œë“œí•˜ê³ , ëª¨ë“  íŒŒì¼ì— CP949 ì¸ì½”ë”©ì„ ì ìš©í•˜ì—¬ ë³‘í•©í•©ë‹ˆë‹¤."""
    combined_df = pd.DataFrame()

    if not file_paths_list:
        st.error("ë¡œë“œí•  ê´€ê´‘ì§€ CSV íŒŒì¼ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `TOUR_CSV_FILES`ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    for file_path in file_paths_list:
        if not os.path.exists(file_path):
            st.warning(f"'{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤. (Streamlit Cloudì—ì„œëŠ” í•´ë‹¹ íŒŒì¼ë“¤ì´ Git ë¦¬í¬ì§€í† ë¦¬ì— í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)")
            continue

        current_encoding = 'cp494' # CP949 ì¸ì½”ë”©ìœ¼ë¡œ ì§€ì •

        try:
            # GitHubì— íŒŒì¼ì´ ìˆë‹¤ë©´, Streamlitì€ í•´ë‹¹ ê²½ë¡œì—ì„œ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
            df = pd.read_csv(file_path, encoding=current_encoding)
            df.columns = df.columns.str.strip()

            if "ìœ„ë„" not in df.columns or "ê²½ë„" not in df.columns:
                st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ì€ 'ìœ„ë„', 'ê²½ë„' ì»¬ëŸ¼ì´ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤.")
                continue

            name_col = None
            for candidate in ["ê´€ê´‘ì§€ëª…", "ê´€ê´‘ì •ë³´ëª…","ê´€ê´‘ì§€"]:
                if candidate in df.columns:
                    name_col = candidate
                    break

            if name_col is None:
                df["ê´€ê´‘ì§€ëª…"] = "ì´ë¦„ ì—†ìŒ"
            else:
                df["ê´€ê´‘ì§€ëª…"] = df[name_col]

            address_col = None
            for candidate in ["ì •ì œë„ë¡œëª…ì£¼ì†Œ","ì •ì œì§€ë²ˆì£¼ì†Œ","ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ","ì†Œì¬ì§€ì§€ë²ˆì£¼ì†Œ","ê´€ê´‘ì§€ì†Œì¬ì§€ì§€ë²ˆì£¼ì†Œ","ê´€ê´‘ì§€ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"]:
                if candidate in df.columns:
                    address_col = candidate
                    break

            if address_col is None:
                df["ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"] = "ì£¼ì†Œ ì—†ìŒ"
            else:
                df["ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"] = df[address_col]

            df = df[["ìœ„ë„", "ê²½ë„", "ê´€ê´‘ì§€ëª…", "ì†Œì¬ì§€ë„ë¡œëª…ì£¼ì†Œ"]]

            combined_df = pd.concat([combined_df, df], ignore_index=True)

        except Exception as e:
            st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ ({current_encoding} ì¸ì½”ë”© ì‹œë„) ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if combined_df.empty:
        st.error("ì§€ì •ëœ íŒŒì¼ë“¤ì—ì„œ ìœ íš¨í•œ ê´€ê´‘ì§€ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. `TOUR_CSV_FILES`ì™€ íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    return combined_df


# --- ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© ë° ìºì‹± ---
@st.cache_resource
def load_and_create_vectorstore_from_specific_files(tour_csv_files_list):
    """ì§€ì •ëœ CSV íŒŒì¼ ëª©ë¡ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    all_city_tour_docs = []
    for file_path in tour_csv_files_list:
        if not os.path.exists(file_path):
            st.warning(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„±ì„ ìœ„í•´ '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆëœ±ë‹ˆë‹¤.")
            continue

        current_encoding = 'cp949'

        try:
            # CSVLoaderë„ GitHub ì €ì¥ì†Œ ë‚´ì˜ ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.
            city_tour_loader = CSVLoader(file_path=file_path, encoding=current_encoding, csv_args={'delimiter': ','})
            all_city_tour_docs.extend(city_tour_loader.load())
        except Exception as e:
            st.warning(f"'{os.path.basename(file_path)}' íŒŒì¼ ({current_encoding} ì¸ì½”ë”© ì‹œë„) ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë²¡í„°ìŠ¤í† ì–´): {e}")

    all_documents = all_city_tour_docs

    if not all_documents:
        st.error("ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)
    docs = text_splitter.split_documents(all_documents)
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(docs, embeddings)
    # ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì‹œì—ë„ Streamlit ì•±ì´ ì‹¤í–‰ë˜ëŠ” í™˜ê²½ì˜ ë¡œì»¬ ê²½ë¡œì— ì €ì¥ë©ë‹ˆë‹¤.
    # Streamlit Cloudì—ì„œëŠ” ì»¨í…Œì´ë„ˆ ë‚´ì˜ ì„ì‹œ ì €ì¥ì†Œì— ì €ì¥ë˜ë©°, ë‹¤ìŒ ì„¸ì…˜ì—ì„œ ì¬í™œìš©ë©ë‹ˆë‹¤.
    vectorstore.save_local(VECTOR_DB_PATH)
    return vectorstore

@st.cache_resource()
def get_vectorstore_cached(tour_csv_files_list):
    """ìºì‹œëœ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤."""
    # os.path.exists(VECTOR_DB_PATH)ë¡œ ì´ë¯¸ ìƒì„±ëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    if os.path.exists(VECTOR_DB_PATH):
        try:
            return FAISS.load_local(
                VECTOR_DB_PATH,
                OpenAIEmbeddings(),
                allow_dangerous_deserialization=True
            )
        except Exception as e:
            st.warning(f"ê¸°ì¡´ ë²¡í„° DB ë¡œë”© ì‹¤íŒ¨: {e}. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            return load_and_create_vectorstore_from_specific_files(tour_csv_files_list)
    else:
        return load_and_create_vectorstore_from_specific_files(tour_csv_files_list)


# --- Haversine distance function ---
def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # Radius of Earth in kilometers
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    distance = R * c
    return distance

# --- 3. ì‚¬ìš©ì ì…ë ¥ ë° UI ë¡œì§ í•¨ìˆ˜ ---
def get_user_inputs_ui():
    """ì‚¬ìš©ìë¡œë¶€í„° ë‚˜ì´, ì—¬í–‰ ìŠ¤íƒ€ì¼, í˜„ì¬ ìœ„ì¹˜, ê·¸ë¦¬ê³  ì¶”ê°€ ì—¬í–‰ ê³„íš ì •ë³´ë¥¼ ì…ë ¥ë°›ëŠ” UIë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.markdown("#### ì‚¬ìš©ì ì •ë³´ ì…ë ¥")
        age = st.selectbox("ë‚˜ì´ëŒ€ ì„ íƒ", ["10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€ ì´ìƒ"], key='age_selectbox')
        travel_style = st.multiselect("ì—¬í–‰ ìŠ¤íƒ€ì¼", ["ìì—°", "ì—­ì‚¬", "ì²´í—˜", "íœ´ì‹", "ë¬¸í™”", "ê°€ì¡±", "ì•¡í‹°ë¹„í‹°"], key='travel_style_multiselect')

    st.header("â‘  ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°")
    location = streamlit_geolocation()

    user_lat_final, user_lon_final = None, None

    if location and "latitude" in location and "longitude" in location:
        temp_lat = location.get("latitude")
        temp_lon = location.get("longitude")
        if temp_lat is not None and temp_lon is not None:
            user_lat_final = temp_lat
            user_lon_final = temp_lon
            st.success(f"ğŸ“ í˜„ì¬ ìœ„ì¹˜: ìœ„ë„ {user_lat_final:.7f}, ê²½ë„ {user_lon_final:.7f}")
        else:
            st.warning("ğŸ“ ìœ„ì¹˜ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        st.warning("ìœ„ì¹˜ ì •ë³´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ìœ„ë„, ê²½ë„ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

    if user_lat_final is None or user_lon_final is None:
        default_lat = st.session_state.get("user_lat", 37.5665) # ì„œìš¸ ì‹œì²­ ê¸°ë³¸ ìœ„ë„
        default_lon = st.session_state.get("user_lon", 126.9780) # ì„œìš¸ ì‹œì²­ ê¸°ë³¸ ê²½ë„

        st.subheader("ì§ì ‘ ìœ„ì¹˜ ì…ë ¥ (ì„ íƒ ì‚¬í•­)")
        manual_lat = st.number_input("ìœ„ë„", value=float(default_lat), format="%.7f", key="manual_lat_input")
        manual_lon = st.number_input("ê²½ë„", value=float(default_lon), format="%.7f", key="manual_lon_input")

        if manual_lat != 0.0 or manual_lon != 0.0:
            user_lat_final = manual_lat
            user_lon_final = manual_lon
        else:
            user_lat_final = None
            user_lon_final = None
            st.error("ìœ íš¨í•œ ìœ„ë„ ë° ê²½ë„ ê°’ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 0ì´ ì•„ë‹Œ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    st.session_state.user_lat = user_lat_final
    st.session_state.user_lon = user_lon_final

    st.markdown("#### ì¶”ê°€ ì—¬í–‰ ê³„íš ì •ë³´")
    trip_duration_days = st.number_input("ì—¬í–‰ ê¸°ê°„ (ì¼)", min_value=1, value=3, key='trip_duration')
    estimated_budget = st.number_input("ì˜ˆìƒ ì˜ˆì‚° (ì›, ì´ ê¸ˆì•¡)", min_value=0, value=500000, step=10000, key='estimated_budget')
    num_travelers = st.number_input("ì—¬í–‰ ì¸ì› (ëª…)", min_value=1, value=2, key='num_travelers')
    special_requests = st.text_area("íŠ¹ë³„íˆ ê³ ë ¤í•  ì‚¬í•­ (ì„ íƒ ì‚¬í•­)", help="ì˜ˆ: ìœ ëª¨ì°¨ ì‚¬ìš©, ê³ ë ¹ì ë™ë°˜, íŠ¹ì • ìŒì‹ ì„ í˜¸ ë“±", key='special_requests')

    return age, travel_style, user_lat_final, user_lon_final, trip_duration_days, estimated_budget, num_travelers, special_requests

# --- 4. ì¶”ì²œ ë¡œì§ í•¨ìˆ˜ (Langchain API ë³€ê²½: create_retrieval_chain ì‚¬ìš©) (í”„ë¡¬í”„íŠ¸ ìˆ˜ì •) ---
@st.cache_resource
def get_qa_chain(_vectorstore):
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0.7)

    qa_prompt = PromptTemplate.from_template(
        """
ë‹¹ì‹ ì€ ì‚¬ìš©ì ìœ„ì¹˜ ê¸°ë°˜ ì—¬í–‰ì§€ ì¶”ì²œ ë° ìƒì„¸ ì—¬í–‰ ê³„íš ìˆ˜ë¦½ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ë‚˜ì´ëŒ€, ì—¬í–‰ ì„±í–¥, í˜„ì¬ ìœ„ì¹˜ ì •ë³´, ê·¸ë¦¬ê³  ë‹¤ìŒì˜ ì¶”ê°€ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½í•´ ì£¼ì„¸ìš”.
**ê´€ê´‘ì§€ ì¶”ì²œ ì‹œ ì‚¬ìš©ì ìœ„ì¹˜ë¡œë¶€í„°ì˜ ê±°ë¦¬ëŠ” ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¶”ê°€í•  ê²ƒì´ë¯€ë¡œ, ë‹µë³€ì—ì„œ ê±°ë¦¬ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
íŠ¹íˆ, ì‚¬ìš©ìì˜ í˜„ì¬ ìœ„ì¹˜({user_lat}, {user_lon})ì—ì„œ ê°€ê¹Œìš´ ì¥ì†Œë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì¶”ì²œí•˜ê³  ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”.
ê¼­ê¼­ ì‚¬ìš©ì í˜„ì¬ ìœ„ì¹˜ì™€ ê°€ê¹Œìš´ ê³³ì„ ìµœìš°ì„ ìœ¼ë¡œ í•´ì£¼ê³  ì‚¬ìš©ìê°€ ì„ íƒí•œ ì„±í–¥ì— ë§ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

[ê´€ê´‘ì§€ ë°ì´í„°]
{context}

[ì‚¬ìš©ì ì •ë³´]
ë‚˜ì´ëŒ€: {age}
ì—¬í–‰ ì„±í–¥: {travel_style}
í˜„ì¬ ìœ„ì¹˜ (ìœ„ë„, ê²½ë„): {user_lat}, {user_lon}
ì—¬í–‰ ê¸°ê°„: {trip_duration_days}ì¼
ì˜ˆìƒ ì˜ˆì‚°: {estimated_budget}ì›
ì—¬í–‰ ì¸ì›: {num_travelers}ëª…
íŠ¹ë³„ ê³ ë ¤ì‚¬í•­: {special_requests}

[ì‚¬ìš©ì ì§ˆë¬¸]
{input}

ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ìƒì„¸í•œ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”:
1.  **ê´€ê´‘ì§€ ì¶”ì²œ:** ì§ˆë¬¸ì— ë¶€í•©í•˜ê³ , ì‚¬ìš©ì ìœ„ì¹˜ì—ì„œ ê°€ê¹Œìš´ 1~3ê°œì˜ ì£¼ìš” ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê³ , ê° ê´€ê´‘ì§€ì— ëŒ€í•œ ë‹¤ìŒ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.
    * ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª…]
    * ì£¼ì†Œ: [ì£¼ì†Œ]
    * ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´]
    **[ì°¸ê³ : ì‚¬ìš©ì ìœ„ì¹˜ ê¸°ì¤€ ê±°ë¦¬ëŠ” ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ê³„ì‚°í•˜ì—¬ ì¶”ê°€í•  ê²ƒì´ë¯€ë¡œ, ì´ í•­ëª©ì€ ì œì™¸í•©ë‹ˆë‹¤.]**
    
2.  **ì¶”ì²œëœ ê´€ê´‘ì§€ë¥¼ í¬í•¨í•˜ì—¬, ì‚¬ìš©ì ì •ë³´ì™€ ì§ˆë¬¸ì— ê¸°ë°˜í•œ {trip_duration_days}ì¼ê°„ì˜ ìƒì„¸ ì—¬í–‰ ê³„íšì„ ì¼ìë³„ë¡œ êµ¬ì„±í•´ ì£¼ì„¸ìš”.**
    * ê° ë‚ ì§œë³„ë¡œ ë°©ë¬¸í•  ì¥ì†Œ(ì‹ë‹¹, ì¹´í˜, ê¸°íƒ€ í™œë™ í¬í•¨), ì˜ˆìƒ ì‹œê°„, ê°„ë‹¨í•œ í™œë™ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.
    * ì˜ˆì‚°ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ì‹ì‚¬ ì¥ì†Œë‚˜ í™œë™ì„ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    * ì´ë™ ê²½ë¡œ(ì˜ˆ: "ë„ë³´ 15ë¶„", "ë²„ìŠ¤ 30ë¶„")ë¥¼ ê°„ëµí•˜ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.
    * ê³„íšì€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

[ë‹µë³€ ì˜ˆì‹œ]
**ì¶”ì²œ ê´€ê´‘ì§€:**
- ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª… 1]
  - ì£¼ì†Œ: [ì£¼ì†Œ 1]
  - ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´ 1]
- ê´€ê´‘ì§€ ì´ë¦„: [ê´€ê´‘ì§€ëª… 2]
  - ì£¼ì†Œ: [ì£¼ì†Œ 2]
  - ì£¼ìš” ì‹œì„¤/íŠ¹ì§•: [ì •ë³´ 2]

**ìƒì„¸ ì—¬í–‰ ê³„íš ({trip_duration_days}ì¼):**
ë‹¤ìŒ í‘œ í˜•ì‹ìœ¼ë¡œ ì¼ìë³„ ìƒì„¸ ê³„íšì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ì»¬ëŸ¼ëª…ì€ 'ì¼ì°¨', 'ì‹œê°„', 'í™œë™', 'ì˜ˆìƒ ì¥ì†Œ', 'ì´ë™ ë°©ë²•'ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.
| ì¼ì°¨ | ì‹œê°„ | í™œë™ | ì˜ˆìƒ ì¥ì†Œ | ì´ë™ ë°©ë²• |
|---|---|---|---|---|
| 1ì¼ì°¨ | ì˜¤ì „ (9:00 - 12:00) | [í™œë™ ë‚´ìš©] | [ì¥ì†Œëª…] | [ì´ë™ ë°©ë²•] |
| 1ì¼ì°¨ | ì ì‹¬ (12:00 - 13:00) | [ì‹ì‚¬] | [ì‹ë‹¹ëª…] | - |
| 1ì¼ì°¨ | ì˜¤í›„ (13:00 - 17:00) | [í™œë™ ë‚´ìš©] | [ì¥ì†Œëª…] | [ì´ë™ ë°©ë²•] |
| 1ì¼ì°¨ | ì €ë… (17:00 ì´í›„) | [í™œë™ ë‚´ìš©] | [ì¥ì†Œëª… ë˜ëŠ” ììœ  ì‹œê°„] | - |
| 2ì¼ì°¨ | ... | ... | ... | ... |
**ì¤‘ìš”: 'ì¼ì°¨' ì»¬ëŸ¼ì˜ ê²½ìš°, ê°™ì€ ì¼ì°¨ì˜ ì—¬ëŸ¬ í™œë™ì´ ìˆì„ ê²½ìš° ì²« ë²ˆì§¸ í™œë™ì—ë§Œ í•´ë‹¹ 'ì¼ì°¨'ë¥¼ ëª…ì‹œí•˜ê³ , ë‚˜ë¨¸ì§€ í™œë™ í–‰ì˜ 'ì¼ì°¨' ì…€ì€ ë¹„ì›Œë‘ì„¸ìš” (ì˜ˆ: "| | ì‹œê°„ | í™œë™ | ì˜ˆìƒ ì¥ì†Œ | ì´ë™ ë°©ë²• |"). ì´ë ‡ê²Œ í•´ì•¼ í‘œì—ì„œ 'ì¼ì°¨'ê°€ ìë™ìœ¼ë¡œ ë³‘í•©ë˜ì–´ ë³´ì…ë‹ˆë‹¤.**
"""
    )
    document_chain = create_stuff_documents_chain(llm, qa_prompt)
    retriever = _vectorstore.as_retriever(search_kwargs={"k": 15})
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    return retrieval_chain


# --- 5. ë©”ì¸ ì•± ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    openai_api_key = setup_environment()
    if not openai_api_key:
        st.stop()

    # Streamlit ì•±ì˜ ë°°ê²½ ìƒ‰ìƒ ì„¤ì •
    st.markdown(
        """
        <style>
        .stApp {
            background-color: #8DB600; /* ì—°ìƒ‰ ê³„ì—´ */
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”: 'app_started' í”Œë˜ê·¸ ì¶”ê°€
    if "app_started" not in st.session_state:
        st.session_state.app_started = False
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ë° ì´ì „ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
    # 'messages' ì„¸ì…˜ ìƒíƒœëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±° ë¡œì§ ì¶”ê°€
    if "conversations" not in st.session_state:
        st.session_state.conversations = []
        st.session_state.current_input = ""
        st.session_state.selected_conversation_index = None
    if "messages" in st.session_state: # ê¸°ì¡´ messages ìƒíƒœê°€ ë‚¨ì•„ìˆì„ ê²½ìš° ì‚­ì œ
        del st.session_state.messages

    # ì‹œì‘ í™”ë©´
    if not st.session_state.app_started:
        st.title("ğŸš‚ë– ë‚˜ì! ë§ì¶¤í˜• ì—¬í–‰ ê³„íš ì±—ë´‡")
        st.markdown("### ë‹¹ì‹ ì˜ ì™„ë²½í•œ ì—¬í–‰ì„ ìœ„í•œ AI íŒŒíŠ¸ë„ˆ")
        
        st.image("./trainj.pg", 
                 caption="ì—¬í–‰ì˜ ì‹œì‘ì€ ì§€ê¸ˆë¶€í„°!", 
                 use_container_width=True) # ìˆ˜ì •ëœ ë¶€ë¶„: use_column_width -> use_container_width
        
        st.write("""
        ì´ ì±—ë´‡ì€ ë‹¹ì‹ ì˜ ë‚˜ì´ëŒ€, ì—¬í–‰ ìŠ¤íƒ€ì¼, í˜„ì¬ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ê´€ê´‘ì§€ë¥¼ ì¶”ì²œí•˜ê³ , 
        ìƒì„¸í•œ ì¼ìë³„ ì—¬í–‰ ê³„íšì„ ì„¸ì›Œì¤ë‹ˆë‹¤. 
        ì´ì œ ë²ˆê±°ë¡œìš´ ê³„íšì€ AIì—ê²Œ ë§¡ê¸°ê³  ì¦ê±°ìš´ ì—¬í–‰ë§Œ ì¤€ë¹„í•˜ì„¸ìš”!
        """)
        
        if st.button("ğŸš‚ì—¬í–‰ ê³„íš ì‹œì‘í•˜ê¸°"):
            st.session_state.app_started = True
            st.rerun() # ì•± ë‹¤ì‹œ ì‹œì‘í•˜ì—¬ ì±—ë´‡ í™”ë©´ìœ¼ë¡œ ì „í™˜

    else: # ì•± ì‹œì‘ í”Œë˜ê·¸ê°€ Trueì¸ ê²½ìš° ì±—ë´‡ í™”ë©´ í‘œì‹œ
        st.title("ğŸ—ºï¸ ìœ„ì¹˜ ê¸°ë°˜ ê´€ê´‘ì§€ ì¶”ì²œ ë° ì—¬í–‰ ê³„íš ì±—ë´‡")
        vectorstore = get_vectorstore_cached(TOUR_CSV_FILES)
        tour_data_df = load_specific_tour_data(TOUR_CSV_FILES)
        qa_chain = get_qa_chain(vectorstore) # DataFrame ë¡œë“œ í›„ qa_chain ì´ˆê¸°í™”

        # Sidebar for previous conversations
        with st.sidebar:
            st.subheader("ğŸ’¡ì´ì „ ëŒ€í™”")
            if st.session_state.conversations:
                # ìµœì‹  ëŒ€í™”ë¥¼ ë¨¼ì € ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì—­ìˆœìœ¼ë¡œ ë°˜ë³µ
                for i, conv in enumerate(reversed(st.session_state.conversations)):
                    original_index = len(st.session_state.conversations) - 1 - i
                    
                    if 'travel_style_selected' in conv and conv['travel_style_selected'] and conv['travel_style_selected'] != 'íŠ¹ì • ì—†ìŒ':
                        preview_text = f"ì„±í–¥: {conv['travel_style_selected']}"
                        # ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„
                        if len(preview_text) > 25:
                            preview_text = preview_text[:22] + '...'
                    else:
                        preview_text = conv['user_query'][:25] + ('...' if len(conv['user_query']) > 25 else '')
                        
                    if st.button(f"ëŒ€í™” {original_index + 1}: {preview_text}", key=f"sidebar_conv_{original_index}"):
                        st.session_state.selected_conversation_index = original_index
                        st.rerun()

            else:
                st.info("ì´ì „ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # --- ë©”ì¸ ì½˜í…ì¸  ì˜ì—­ ---
        if st.session_state.selected_conversation_index is not None:
            st.header("ì´ì „ ëŒ€í™” ë‚´ìš©")
            
            selected_conv = st.session_state.conversations[st.session_state.selected_conversation_index]
            
            st.subheader("ì§ˆë¬¸:")
            st.markdown(selected_conv['user_query'])
            
            if 'travel_style_selected' in selected_conv and selected_conv['travel_style_selected'] and selected_conv['travel_style_selected'] != 'íŠ¹ì • ì—†ìŒ':
                st.subheader("ì„±í–¥:")
                st.markdown(selected_conv['travel_style_selected'])

            st.subheader("ë‹µë³€:")
            st.markdown(selected_conv['chatbot_response']) # ì›ë³¸ í…ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì¤Œ
            
            st.markdown("---")
            if st.button("ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘í•˜ê¸°"):
                st.session_state.selected_conversation_index = None
                st.session_state.current_input = ""
                st.rerun()

        else: # ì´ì „ ëŒ€í™”ê°€ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš° (ìƒˆë¡œìš´ ì§ˆë¬¸ ì…ë ¥ ìƒíƒœ)
            age, travel_style_list, current_user_lat, current_user_lon, \
            trip_duration_days, estimated_budget, num_travelers, special_requests = get_user_inputs_ui()

            st.header("â‘¡ ì§ˆë¬¸í•˜ê¸°")
            user_query = st.text_input("ì–´ë–¤ ì—¬í–‰ì„ ê³„íší•˜ê³  ê³„ì‹ ê°€ìš”? (ì˜ˆ: ê°€ì¡±ê³¼ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ìì—° í…Œë§ˆ ì—¬í–‰)", value=st.session_state.current_input, key="user_input")

            if st.button("ì—¬í–‰ ê³„íš ì¶”ì²œë°›ê¸°"):
                st.session_state.selected_conversation_index = None

                lat_to_invoke = current_user_lat
                lon_to_invoke = current_user_lon

                age_to_invoke = age
                travel_style_to_invoke = ', '.join(travel_style_list) if travel_style_list else 'íŠ¹ì • ì—†ìŒ'
                trip_duration_days_to_invoke = trip_duration_days
                estimated_budget_to_invoke = estimated_budget
                num_travelers_to_invoke = num_travelers
                special_requests_to_invoke = special_requests

                if lat_to_invoke is None or lon_to_invoke is None:
                    st.warning("ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì¹˜ ì •ë³´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ê°€ì ¸ì™€ ì£¼ì„¸ìš”.")
                elif not user_query.strip():
                    st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("ìµœì ì˜ ì—¬í–‰ ê³„íšì„ ìˆ˜ë¦½ ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            response = qa_chain.invoke({
                                "input": user_query,
                                "age": age_to_invoke,
                                "travel_style": travel_style_to_invoke,
                                "user_lat": lat_to_invoke,
                                "user_lon": lon_to_invoke,
                                "trip_duration_days": trip_duration_days_to_invoke,
                                "estimated_budget": estimated_budget_to_invoke,
                                "num_travelers": num_travelers_to_invoke,
                                "special_requests": special_requests_to_invoke
                            })

                            rag_result_text = response["answer"]

                            processed_output_lines = []
                            processed_place_names = set()
                            table_plan_text = ""
                            in_plan_section = False

                            for line in rag_result_text.split('\n'):
                                if "ìƒì„¸ ì—¬í–‰ ê³„íš" in line and "ì¼ì°¨ | ì‹œê°„ | í™œë™" not in line:
                                    processed_output_lines.append(line)
                                    in_plan_section = True
                                    continue

                                if not in_plan_section:
                                    name_match = re.search(r"ê´€ê´‘ì§€ ì´ë¦„:\s*(.+)", line)
                                    if name_match:
                                        current_place_name = name_match.group(1).strip()
                                        if current_place_name not in processed_place_names:
                                            processed_output_lines.append(line)
                                            processed_place_names.add(current_place_name)

                                            found_place_data = tour_data_df[
                                                (tour_data_df['ê´€ê´‘ì§€ëª…'].str.strip() == current_place_name) &
                                                (pd.notna(tour_data_df['ìœ„ë„'])) &
                                                (pd.notna(tour_data_df['ê²½ë„']))
                                            ]
                                            if not found_place_data.empty:
                                                place_lat = found_place_data['ìœ„ë„'].iloc[0]
                                                place_lon = found_place_data['ê²½ë„'].iloc[0]
                                                distance = haversine(lat_to_invoke, lon_to_invoke, place_lat, place_lon)
                                                processed_output_lines.append(f"- ì‚¬ìš©ì ìœ„ì¹˜ ê¸°ì¤€ ê±°ë¦¬(km): ì•½ {distance:.2f} km")
                                            else:
                                                processed_output_lines.append("- ì‚¬ìš©ì ìœ„ì¹˜ ê¸°ì¤€ ê±°ë¦¬(km): ì •ë³´ ì—†ìŒ (ë°ì´í„° ë¶ˆì¼ì¹˜ ë˜ëŠ” ì¢Œí‘œ ëˆ„ë½)")
                                    else:
                                        if not re.search(r"ê±°ë¦¬\(km\):", line):
                                            processed_output_lines.append(line)
                                else:
                                    table_plan_text += line + "\n"

                            st.subheader("ì¶”ì²œ ê²°ê³¼ ë° ìƒì„¸ ì—¬í–‰ ê³„íš")
                            st.markdown("\n".join(processed_output_lines))

                            if table_plan_text.strip():
                                try:
                                    plan_lines = table_plan_text.strip().split('\n')
                                    
                                    if len(plan_lines) >= 2 and plan_lines[0].count('|') >= 2 and plan_lines[1].count('|') >= 2 and all(re.match(r'^-+$', s.strip()) for s in plan_lines[1].split('|') if s.strip()):
                                        header = [h.strip() for h in plan_lines[0].split('|') if h.strip()]
                                        data_rows = []
                                        for row_str in plan_lines[2:]:
                                            if row_str.strip() and row_str.startswith('|'):
                                                parsed_row = [d.strip() for d in row_str.split('|')]
                                                if parsed_row and parsed_row[0] == '':
                                                    parsed_row = parsed_row[1:]
                                                if parsed_row and parsed_row[-1] == '':
                                                    parsed_row = parsed_row[:-1]
                                                data_rows.append(parsed_row)

                                        if data_rows:
                                            if all(len(row) == len(header) for row in data_rows):
                                                temp_plan_df = pd.DataFrame(data_rows, columns=header)
                                                
                                                if 'ì¼ì°¨' in temp_plan_df.columns:
                                                    for i in range(1, len(temp_plan_df)):
                                                        if temp_plan_df.loc[i, 'ì¼ì°¨'] == temp_plan_df.loc[i-1, 'ì¼ì°¨']:
                                                            temp_plan_df.loc[i, 'ì¼ì°¨'] = ''
                                                    
                                                    plan_df_styled = temp_plan_df.set_index('ì¼ì°¨')
                                                    
                                                    st.subheader("ğŸ—“ï¸ì¶”ì²œì—¬í–‰ê³„íší‘œ")
                                                    st.dataframe(plan_df_styled, use_container_width=True)
                                                else:
                                                    st.subheader("ğŸ—“ï¸ì¶”ì²œì—¬í–‰ê³„íší‘œí‘œ")
                                                    st.dataframe(temp_plan_df, use_container_width=True)
                                                    st.warning("ì—¬í–‰ ê³„íšì— 'ì¼ì°¨' ì»¬ëŸ¼ì´ ì—†ì–´ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                            else:
                                                st.warning("ì—¬í–‰ ê³„íš í…Œì´ë¸”ì˜ í–‰ê³¼ ì—´ì˜ ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ í‘œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ì‘ë‹µ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                        else:
                                            st.warning("ì—¬í–‰ ê³„íš í…Œì´ë¸” ë‚´ìš©ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLMì´ ìš”ì²­ëœ í‘œ í˜•ì‹ì„ ë”°ë¥´ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                    else:
                                        st.warning("ì—¬í–‰ ê³„íšì´ ìœ íš¨í•œ í‘œ í˜•ì‹ìœ¼ë¡œ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                                except Exception as parse_e:
                                    st.error(f"ì—¬í–‰ ê³„íš í…Œì´ë¸” íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {parse_e}. LLM ì‘ë‹µ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            else:
                                st.info("ìƒì„¸ ì—¬í–‰ ê³„íšì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                            
                            st.session_state.conversations.append({
                                "user_query": user_query,
                                "chatbot_response": rag_result_text,
                                "travel_style_selected": travel_style_to_invoke
                            })

                        except ValueError as ve:
                            st.error(f"ì²´ì¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {ve}. ì…ë ¥ í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        except Exception as e:
                            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

                st.session_state.current_input = "" # ì…ë ¥ì°½ ì´ˆê¸°í™”
